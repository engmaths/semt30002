[
  {
    "objectID": "assessment.html",
    "href": "assessment.html",
    "title": "Assessment",
    "section": "",
    "text": "This unit will be assessed by a single piece of coursework that is to be completed individually. It will be released in two parts, one in week 5 and one in week 9. Details of the coursework will be released on Blackboard.\nThe final deadline is 1 pm on Thursday of week 11 (4 December 2025). Submit your coursework as a .zip file on Blackboard."
  },
  {
    "objectID": "scicomp/timing_code.html",
    "href": "scicomp/timing_code.html",
    "title": "Timing code in Python and Matlab",
    "section": "",
    "text": "Python\nA simple way to time a piece of code in Python is to use the timeit package:\nimport timeit\nThen, write a Python function that contains all of the code that you want to time. For example,\ndef timed_code():\n    A = np.eye(5000)\n    b = np.random.random(5000)\n    x = np.linalg.solve(A, b)\nThe next step is to call the timeit function from the timeit package as follows:\ntime = timeit.timeit(lambda: timed_code(), number = 1)\nThis will run the timed_code function one time. The time in seconds will then be stored in the Python variable time, which can then be printed to the screen.\nFor fast functions, more accurate timings can be obtained by running the function multiple times. This is possible by increasing the value of the number argument. The time that is returned by timeit will the total time. Dividing the total time by the number of times the function was called with give an accurate average value.\nYou can learn more about the timeit package here\n\n\nMatlab\nTiming code in Matlab is very easy; this can be done using the tic and toc functions. For example, in the command window you can type\ntic \nA = eye(5000)\nb = rand(5000, 1)\nx = A \\ b\ntoc\nAfter the toc function is called, the elapsed time since tic was called will be printed to the screen. It’s usually better to write the code that you want to time in a function and then call that function in between the tic and toc.\nYou can find out more about timing code in Matlab by reading its official page on the topic."
  },
  {
    "objectID": "scicomp/week5.html",
    "href": "scicomp/week5.html",
    "title": "Week 5: The 2D Poisson equation",
    "section": "",
    "text": "\\[\n\\renewcommand{\\vec}[1]{\\boldsymbol{#1}}\n\\newcommand{\\td}[2]{\\frac{\\mathrm{d}#1}{\\mathrm{d}#2}}\n\\newcommand{\\tdd}[2]{\\frac{\\mathrm{d}^2#1}{\\mathrm{d}#2^2}}\n\\newcommand{\\pd}[2]{\\frac{\\partial#1}{\\partial#2}}\n\\newcommand{\\pdd}[2]{\\frac{\\partial^2#1}{\\partial#2^2}}\n\\]\n\nOverview\nThis week, we will use finite differences to solve PDEs in two dimensions. Particular focus will be placed on solving Poisson’s equation. For 2D problems, the number of unknowns and hence the size of the linear systems quickly grow as the number of grid points is increased. Sparse matrices, which only store the non-zero elements of a matrix, can lead to substantial reductions in the memory that needed to numerically solve the PDE, especially for 2D problems.\n\n\nSupplementary material\n\nExample code for the Poisson equation\nSparse vs dense array comparison code\nPDF of demos\n\n\n\nExercises\nFor the exercises below, you can use the example code for solving Poisson’s equation as a starting point. Alternatively, you can build your own code from scratch to solve the problem using linear algebra functions.\n\nSolve the Poisson equation \\[\n\\nabla^2 u + 2 = 0\n\\] on the domain \\(0 \\leq x \\leq 1\\) and \\(1 \\leq y \\leq 4\\). Assume that \\(u = 0\\) on the boundaries.\nUse memory profiling to determine how much memory is required to solve the problem in Exercise 1. How does the memory usage depend on the number of grid points?\nGeneralise your code from Exercise 1 so that it can solve problems of the form \\[\nD \\nabla^2 u + q(x,y) = 0.\n\\] To validate your code, set \\[\nq(x,y) = D \\pi^2 \\left[\\frac{1}{(b-a)^2} + \\frac{1}{(d-c)^2}\\right]\\sin\\left[\\frac{\\pi(x-a)}{b-a}\\right]\\sin\\left[\\frac{\\pi(y-c)}{d-c}\\right];\n\\] in this case, the exact solution to the problem is given by \\[\nu(x,y) = \\sin\\left[\\frac{\\pi(x-a)}{b-a}\\right]\\sin\\left[\\frac{\\pi(y-c)}{d-c}\\right].\n\\]\nFurther generalise your code so that non-homogeneous Dirichlet boundary conditions can be used. For example, solve the Poisson equation for Exercise 1 but replace the boundary condition at \\(x = a\\) with \\(u(a, y) = \\sin(\\pi(y-c)/(d-c))\\).\nUse sparse matrices to solve the 1D Poisson equation given by \\[\n\\tdd{u}{x} + 1 = 0\n\\] with \\(u(0) = u(1) = 0\\).\n\nFirst use 101 grid points (\\(N = 100\\)). Time your code and profile its memory usage. Is your sparse code faster and more memory efficient than your previous code?\nRepeat part (a) but now use \\(N = 1000\\). If you have correctly implemented sparse matrices, then you should now see a significant speed up and memory reduction.\n\nSolve the 2D Poisson equation with sparse matrices. Use memory profiling to examine the memory saved by using sparse matrices."
  },
  {
    "objectID": "scicomp/poisson_example.html",
    "href": "scicomp/poisson_example.html",
    "title": "Example code for the 2D Poisson equation",
    "section": "",
    "text": "\\[\n\\renewcommand{\\vec}[1]{\\boldsymbol{#1}}\n\\newcommand{\\td}[2]{\\frac{\\mathrm{d}#1}{\\mathrm{d}#2}}\n\\newcommand{\\tdd}[2]{\\frac{\\mathrm{d}^2#1}{\\mathrm{d}#2^2}}\n\\newcommand{\\pd}[2]{\\frac{\\partial#1}{\\partial#2}}\n\\newcommand{\\pdd}[2]{\\frac{\\partial^2#1}{\\partial#2^2}}\n\\]\n\nOverview\nThe code below solves the Poisson equation \\[\n\\pdd{u}{x} + \\pdd{u}{y} + q = 0\n\\] where \\(q\\) is a constant on a rectangular domain given by \\(a \\leq x \\leq b\\) and \\(c \\leq y \\leq d\\). Dirichlet boundary conditions given by \\(u = 0\\) are imposed at all four boundaries.\n\n\nCode\n\nimport numpy as np\nfrom scipy.optimize import root\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\n\n\"\"\" \nset up the problem parameters\n\"\"\"\n\n# domain parameters\na = 0\nb = 1\nc = 0\nd = 1\n\n# number of grid points\nNx = 20\nNy = 20\n\n# Value of the constant source term\nq = 1\n\n\"\"\"\nconstruct the grid    \n\"\"\"\n\n# grid points\nx = np.linspace(0, 1, Nx+1)\ny = np.linspace(0, 1, Ny+1)\nx_int = x[1:Nx]\ny_int = y[1:Ny]\n\n# grid spacing in x and y directions\ndx = (b - a) / Nx\ndy = (d - c) / Ny\n\n# total number of unknowns\ndof = (Nx - 1) * (Ny - 1)\nprint('There are', dof, 'unknowns to solve for')\n\n# mapping from grid indices (i,j) to global indices (k)\nk = lambda i,j : i + (Nx - 1) * j\n\n\"\"\"\nSetting the initial guess of the solution, which is assumed\nto be given by u(x,y) = x*y*(1-x)*(1-y).  First we\ncreate this as a 2D array named u_0.  Then we convert\nthe 2D array into a 1D array named U_0.  Notice how the\nmapping function k defined above is used to calculate\nthe indices of the 1D array using the two local grid\nindices i and j\n\"\"\"\n\n# pre-allocate the 2D array\nu_0 = np.zeros((Nx - 1, Ny - 1))\n\n# use a double for loop to create the initial guess as a 2D array\n\nfor i in range(Nx - 1):\n    for j in range(Ny - 1):\n        u_0[i, j] = x_int[i]*y_int[j]*(1-x_int[i])*(1-y_int[j])\n\n# pre-allocate the 1D array\nU_0 = np.zeros((Nx - 1) * (Ny - 1))\n\n# use a double for loop to store each u[i,j] in U_k\nfor i in range(Nx - 1):\n    for j in range(Ny - 1):\n        U_0[k(i,j)] = u_0[i,j]\n\n\n\"\"\"\nFunction to pass to SciPy's root.  This function\nbuilds the algebraic system in the form F(U) = 0,\nwhere U is a 1D array that contains the solution\ncomponents at all interior grid points.  The code\nbelow is not optimal and improvements can be made.\n\"\"\"\n\ndef dirichlet_problem(U):\n\n    # Pre-allocation of 2D arrays\n    u = np.zeros((Nx-1, Ny-1))\n    F = np.zeros((Nx-1, Ny-1))\n\n    # Convert the 1D soln array U[k] into a 2D array u[i,j]\n    for i in range(0, Nx - 1):\n        for j in range(0, Ny - 1):\n            u[i,j] = U[k(i,j)]\n    \n    # Build the algebraic system as a 2D array F[i,j]\n    for i in range(0, Nx - 1):\n        for j in range(0, Ny - 1):\n\n            # near x = a boundary\n            if i == 0 and 0 &lt; j &lt; Ny - 2:\n                F[i,j] = (\n                    (u[i+1,j] - 2 * u[i,j] + 0) / dx**2 + \n                    (u[i,j+1] - 2 * u[i,j] + u[i,j-1]) / dy**2 + \n                    q\n                )\n\n            # near x = b boundary\n            elif i == Nx - 2 and 0 &lt; j &lt; Ny - 2:\n                F[i,j] = (\n                    (0 - 2 * u[i,j] + u[i-1,j]) / dx**2 + \n                    (u[i,j+1] - 2 * u[i,j] + u[i,j-1]) / dy**2 + \n                    q\n                )\n                \n            # near y = c boundary\n            elif j == 0 and 0 &lt; i &lt; Nx - 2:\n                F[i,j] = (\n                    (u[i+1,j] - 2 * u[i,j] + u[i-1,j]) / dx**2 + \n                    (u[i,j+1] - 2 * u[i,j] + 0) / dy**2 + \n                    q\n                )\n\n            # near y = d boundary\n            elif j == Ny - 2 and 0 &lt; i &lt; Nx - 2:\n                F[i,j] = (\n                    (u[i+1,j] - 2 * u[i,j] + u[i-1,j]) / dx**2 + \n                    (0 - 2 * u[i,j] + u[i,j-1]) / dy**2 + \n                    q\n                )\n\n            # near x = a, y = c corner\n            elif i == 0 and j == 0:\n                F[i,j] = (\n                    (u[i+1,j] - 2 * u[i,j] + 0) / dx**2 + \n                    (u[i,j+1] - 2 * u[i,j] + 0) / dy**2 + \n                    q\n                )\n\n            # near x = a, y = d corner\n            elif i == 0 and j == Ny - 2:\n                F[i,j] = (\n                    (u[i+1,j] - 2 * u[i,j] + 0) / dx**2 + \n                    (0 - 2 * u[i,j] + u[i,j-1]) / dy**2 + \n                    q\n                )\n\n            # near x = b, y = c corner\n            elif i == Nx - 2 and j == 0:\n                F[i,j] = (\n                    (0 - 2 * u[i,j] + u[i-1,j]) / dx**2 + \n                    (u[i,j+1] - 2 * u[i,j] + 0) / dy**2 + \n                    q\n                )\n\n            # near x = b, y = d corner\n            elif i == Nx - 2 and j == Ny - 2:\n                F[i,j] = (\n                    (0 - 2 * u[i,j] + u[i-1,j]) / dx**2 + \n                    (0 - 2 * u[i,j] + u[i,j-1]) / dy**2 + \n                    q\n                )\n\n            # grid points not adjacent to a boundary\n            else:\n                F[i,j] = (\n                    (u[i+1,j] - 2 * u[i,j] + u[i-1,j]) / dx**2 + \n                    (u[i,j+1] - 2 * u[i,j] + u[i,j-1]) / dy**2 + \n                    q\n                )\n\n    # Now the 2D array for F[i,j] needs to be converted into a\n    # 1D array of the form F[k]\n    F_1d = np.zeros((Nx-1) * (Ny-1))\n    for i in range(Nx-1):\n        for j in range(Ny-1):\n            F_1d[k(i,j)] = F[i,j]\n\n    \n    # return the 1D array\n    return F_1d\n\n\n\"\"\"\nSolve the algebraic system using SciPy's root function\n\"\"\"\n\n# Solve\nsol = root(dirichlet_problem, U_0)\n\n# Check for convergence\nprint(f'Did root converge: {sol.success}')\nU = sol.x\n\n\"\"\"\nturn the 1D solution array U into a 2D array u\n\"\"\"\nu = np.zeros((Nx-1, Ny-1))\nfor i in range(Nx-1):\n    for j in range(Ny-1):\n        u[i,j] = U[k(i,j)]\n\n\n\"\"\"\nnow we plot the solution\n\"\"\"\n\n# turn the 1D arrays for x_int and y_int\n# into 2D arrays for plotting\nxx, yy, = np.meshgrid(x_int, y_int)\n\n# due to how the global index function k(i,j) is defined\n# we need to plot the transpose of u rather than u\nfig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\nax.plot_surface(xx, yy, u.T, cmap=cm.coolwarm)\nax.set_xlabel(\"x\")\nax.set_ylabel(\"y\")\nax.set_zlabel(\"u\")\nfig.tight_layout()\n\n# contour plots are often better to use because \n# all the features can be seen\nplt.figure()\nplt.contourf(xx, yy, u.T, 50, cmap = cm.coolwarm)\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.colorbar()\n\nplt.show()\n\nThere are 361 unknowns to solve for\nDid root converge: True"
  },
  {
    "objectID": "scicomp/week1.html",
    "href": "scicomp/week1.html",
    "title": "Week 1: Finite differences and Euler’s method",
    "section": "",
    "text": "\\[\n\\renewcommand{\\vec}[1]{\\boldsymbol{#1}}\n\\newcommand{\\td}[2]{\\frac{\\mathrm{d}#1}{\\mathrm{d}#2}}\n\\newcommand{\\tdd}[2]{\\frac{\\mathrm{d}^2#1}{\\mathrm{d}#2^2}}\n\\newcommand{\\pd}[2]{\\frac{\\partial#1}{\\partial#2}}\n\\newcommand{\\pdd}[2]{\\frac{\\partial^2#1}{\\partial#2^2}}\n\\]"
  },
  {
    "objectID": "scicomp/week1.html#coursework-style-problem",
    "href": "scicomp/week1.html#coursework-style-problem",
    "title": "Week 1: Finite differences and Euler’s method",
    "section": "Coursework-style problem",
    "text": "Coursework-style problem\nConsider a pack of \\(N\\) identical lithium-ion batteries that are connected in series. Let \\(i = 1\\) denote the first battery in the pack and \\(i = N\\) denote the last battery in the pack. The other batteries are labelled with \\(i = 2, 3, \\ldots, N - 1\\). Due to the geometry of the pack, only batteries 1 and \\(N\\) are in contact with the environment. Battery \\(i\\) is in contact with batteries \\(i-1\\) and \\(i + 1\\).\nEach battery in the pack acts as a resistor. When an electrical current is drawn from the battery pack, each battery will heat up due to Joule heating. The heat that is generated in battery \\(i\\) will be transferred to batteries \\(i-1\\) and \\(i + 1\\), causing these two batteries to heat up even more. Heat is transferred from one battery to the next until it reaches batteries 1 and \\(N\\), which can then transfer the heat to the air. The more batteries there are, the longer the generated heat remains in the battery pack, and the hotter the pack will get. If the temperature of any battery exceeds 60 \\(^\\circ\\)C, then it will start to degrade. Battery degradation is extremely dangerous, as this can lead to the release of toxic and explosive gases.\nThe aim of this exercise is to simulate the temperature of a battery pack in order to determine whether it is expected to be safe to use.\nAssume that a constant current \\(I\\) is being drawn from the battery pack. If \\(T_i(t)\\) denotes the temperature of battery \\(i\\) at time \\(t\\), then the temperature of each of the batteries can be obtained by solving the ODE system given by \\[\\begin{align}\nc \\td{T_1}{t} &= I^2 R - h(T_{1} - T_\\text{air}) - h(T_{1} - T_{2}), \\tag{2} \\\\\nc \\td{T_i}{t} &= I^2 R - h(T_{i} - T_{i-1}) - h(T_{i} - T_{i+1}), \\quad i = 2, 3, \\ldots, N - 1, \\tag{3} \\\\\nc \\td{T_N}{t} &= I^2 R - h(T_{N} - T_\\text{air}) - h(T_{N} - T_{N-1}). \\tag{4}\n\\end{align}\\] Here, \\(c\\) is the specific heat of the battery, \\(R\\) is the resistance of the battery, \\(h\\) is the heat transfer coefficient, and \\(T_\\text{air}\\) is the temperature of the air. Values for these parameters are given in the table below. You can assume that the initial temperature of each battery is given by \\(T_\\text{air}\\); that is, \\(T_i(0) = T_\\text{air}\\).\n\nParameter values for each battery.\n\n\n\n\n\n\n\n\n\n\\(I\\) (A)\n\\(c\\) (J/\\(^\\circ\\)C)\n\\(h\\) (W/\\(^\\circ\\)C)\n\\(T_\\text{air}\\) (\\(^\\circ\\)C)\n\\(R\\) (Ohms)\n\n\n\n\n3\n300\n0.7\n23\n0.4\n\n\n\nIn the exercises below, assume that the current is being drawn for one hour.\n\nConsider a battery pack with \\(N = 5\\) batteries.\n\nNumerically solve the ODE system in (2)–(4). Create a single plot that shows the temperature of each battery as a function of time.\nAt each time \\(t\\), compute the maximum temperature across all 6 batteries. Plot the maximum temperature as a function of time.\nUse your results to determine whether the battery is safe to use. Answer: yes.\n\nIs a battery pack with \\(N = 50\\) batteries safe to use? Answer: no.\nWhat is the largest number of batteries that a pack can contain yet still be safe to use? Answer: 6."
  },
  {
    "objectID": "scicomp/week1.html#answers-to-selected-exercises",
    "href": "scicomp/week1.html#answers-to-selected-exercises",
    "title": "Week 1: Finite differences and Euler’s method",
    "section": "Answers to selected exercises",
    "text": "Answers to selected exercises\n\n\\(C = 5\\) does not lead to a valid differentiation formula. \\(C = -5\\) does lead to a valid differentiation formula that is second-order accurate, with \\(TE = O((\\Delta x)^2)\\).\n\nUse the exact solution to validate your code and see what the numerical solution should look like.\nThe accuracy of the solution increases as \\(N_t\\) increases.\n\nThe parameter \\(\\omega\\) corresponds to the natural frequency of the mass-spring system.\n\nThe error decrease linearly with \\(\\Delta t\\).\n\nThe error increases quadratically with \\(\\omega\\). This result is agrees with theory, as the truncation error is proportional to \\(\\ddot{u}_1\\). From the exact solution, \\(\\ddot{u}_1\\) is proportional to \\(\\omega^2\\). This result implies that the accuracy of Euler’s method not only depends on the size of \\(\\Delta t\\), but also how fast the derivative of the solution is changing."
  },
  {
    "objectID": "optim/week10.html",
    "href": "optim/week10.html",
    "title": "Week 10: Integer programming",
    "section": "",
    "text": "In the following exercises, we will examine how to build integer programs from a given problem statement. The software available (Pyomo, JuMP, etc) can automatically solve most problems (with a big caveat that anything with more than a large handful of variables will take a really long time to solve, unless it has special structure). The real challenge is usually getting a good mathematical formulation."
  },
  {
    "objectID": "optim/week10.html#supplementary-material",
    "href": "optim/week10.html#supplementary-material",
    "title": "Week 10: Integer programming",
    "section": "Supplementary material",
    "text": "Supplementary material\n\nAlgorithms for Optimisation - Discrete optimization\nPyomo Workshop Slides - slide 25 onwards in particular\nVarious integer programming implementations\n\nPython - Pyomo\nJulia - JuMP\nMATLAB - Optimization Toolbox\n\nAdditional integer programming exercises - OR-Notes by J E Beasley"
  },
  {
    "objectID": "optim/week10.html#exercise-1---another-diet-problem",
    "href": "optim/week10.html#exercise-1---another-diet-problem",
    "title": "Week 10: Integer programming",
    "section": "Exercise 1 - another diet problem",
    "text": "Exercise 1 - another diet problem\nConsider (a type of diet problem) the manufacturer of animal feed who is producing feed mix for dairy cattle. In this simple example the feed mix contains two active ingredients and a filler to provide bulk. One kg of feed mix must contain a minimum quantity of each of four nutrients as below:\n\n\n\nNutrient\nA\nB\nC\nD\n\n\n\n\ngram\n90\n50\n20\n2\n\n\n\nwhere the ingredients have the following nutrients and costs:\n\n\n\n\nA\nB\nC\nD\nCost/kg\n\n\n\n\nIngredient 1 (gram/kg)\n100\n80\n40\n10\n40\n\n\nIngredient 2 (gram/kg)\n200\n150\n20\n-\n60\n\n\n\nThanks to http://people.brunel.ac.uk/~mastjjb/jeb/or/moreip.html for this which has a range of other fun problems.\n\nLet \\(x_1\\), \\(x_2\\), and \\(x_3\\) be the amounts in kg of the two active ingredients and the filler. Note \\(x_1+x_2+x_3=1\\) is a constraint. Write down the nutrient constraints, and formulate and solve the (least cost) linear program. (No integer programming yet.)\nSuppose there is a fixed cost of 15 units for incorporating any non-zero amount of ingredient 2. Model this by introducing a new (binary, i.e., 0 or 1) variable \\(y\\) such that \\(y=1\\) if \\(x_2&gt;0\\) with \\(15y\\) added to the cost. Note because \\(x_2\\leq 1\\) automatically holds, we may introduce the constraint \\(x_2\\leq y\\). Formulate the integer linear program and solve.\nSuppose now we need not satisfy all four nutrient constraints but need only satisfy three of them: i.e., whereas before the optimal solution required all four nutrient constraints to be satisfied now the optimal solution could (if it is worthwhile to do so) only have three (any three) of these nutrient constraints satisfied and the fourth violated. Introduce 4 new binary variables and solve the problem. (See source webpage for hints.)"
  },
  {
    "objectID": "optim/week10.html#exercise-2---the-n-queens-problem",
    "href": "optim/week10.html#exercise-2---the-n-queens-problem",
    "title": "Week 10: Integer programming",
    "section": "Exercise 2 - the N-queens problem",
    "text": "Exercise 2 - the N-queens problem\nThe N-queens problem involves placing N chess queens on an N×N chessboard such that no two queens can attack each other. This means no two queens can share the same row, column, or diagonal. The goal is to find a possible arrangements that satisfy these conditions.\n\nRepresent the placement of queens on an N×N chess board as an N×N binary matrix. For a fixed value of N (e.g., N=4), write down the constraints on this binary matrix. Implement this problem in Pyomo/JuMP/the MATLAB Optimization Toolbox to find a solution.\nGeneralise the generation of constraints so you can tackle any value for N. How does the time to compute a solution grow with N?"
  },
  {
    "objectID": "optim/week10.html#exercise-3---extension-the-marriage-problem",
    "href": "optim/week10.html#exercise-3---extension-the-marriage-problem",
    "title": "Week 10: Integer programming",
    "section": "Exercise 3 - (extension) the marriage problem",
    "text": "Exercise 3 - (extension) the marriage problem\nA classical example of bipartite matching.\nDown at the dating agency, we conveniently (this is a mathematical idealisation!) have \\(p\\) men and \\(p\\) women and we assume each person is seeking a monogamous relationship with an individual of the opposite sex. Based on questionnaire data, the agency has computed an incompatibility score \\(c_{ij}\\) for each man \\(i\\) with each woman \\(j\\) — i.e., a value of 0 denotes perfect compatibility. Write the optimal pairing strategy as a linear program and solve. Random cost matrices may be generated with the provided code below.\n\nThis is an example of a so-called bipartite matching problem. Google it, and read about the which is the original way of solving these problems. Try coding up the Hungarian Algorithm.\nPossible extensions to this problem. Differing numbers of men and women — what to do? For simplicity, you might continue to assume two distinct genders, but what about other attachment types, eg if some individuals are bisexual and can thus be paired either with a bisexual individual of the same gender or with a heterosexual individual of the opposite gender. What about polygamy? Model how the programs might change and implement them.\n\n\nPython\ndef generate_incompatibility_matrix(n):\n    mFeature = np.random.rand(n,1)\n    fFeature = np.random.rand(n,1)\n    return np.abs(mFeature - fFeature.T)\n\n\nJulia\nfunction generate_incompatibility_matrix(n)\n    mFeature = rand(n)\n    fFeature = rand(n)\n    return abs.(mFeature .- fFeature')\nend\n\n\nMATLAB\nfunction c = generate_incompatibility_matrix(n)\n    mFeature = rand(n);\n    fFeature = rand(n);\n    c = abs(mFeature - fFeature');\nend"
  },
  {
    "objectID": "optim/week9.html",
    "href": "optim/week9.html",
    "title": "Week 9: Linear programming",
    "section": "",
    "text": "In the following exercises you will learn the basics of Pyomo. Setting up a simple problem is relatively straightforward, but adding extra variables/constraints quickly becomes problematic if you don’t learn how to use its more advanced functionality.\nThese exercises will take you through setting up a basic problem with simple notation before moving to the more advanced functionality on the same problem. Finally, we will tackle a significantly larger problem requiring importing data."
  },
  {
    "objectID": "optim/week9.html#supplementary-material",
    "href": "optim/week9.html#supplementary-material",
    "title": "Week 9: Linear programming",
    "section": "Supplementary material",
    "text": "Supplementary material\n\nAlgorithms for Optimisation - Linear constrained optimization\nPyomo Workshop Slides - slide 25 onwards in particular\nVarious linear programming implementations\n\nPython - Pyomo\nJulia - JuMP\nMATLAB - Optimization Toolbox"
  },
  {
    "objectID": "optim/week9.html#exercise-1---a-simple-diet-problem",
    "href": "optim/week9.html#exercise-1---a-simple-diet-problem",
    "title": "Week 9: Linear programming",
    "section": "Exercise 1 - a simple diet problem",
    "text": "Exercise 1 - a simple diet problem\nThe backdrop to this exercise is https://www.youtube.com/watch?v=36Uj1ZhWqa8; there is no need to watch the video unless you would like a reminder of how linear programming works.\nIn this exercise, a company would like to minimise the cost of “healthy” side dishes for their burgers. They have three basic ingredients: carrot, white cabbage, and pickled cucumbers.\nThe costs (per kg) of each of these ingredients are\n\n\n\nIngredient\nCost\n\n\n\n\nCarrot\n0.75\n\n\nCabbage\n0.50\n\n\nCucumber\n0.15\n\n\n\nTheir nutritional contents, with requirements per side dish, are\n\n\n\nNutrition\nCarrot\nCabbage\nCucumber\nRequirement\n\n\n\n\nVitamin A (mg/kg)\n35\n0.5\n0.5\n0.5mg\n\n\nVitamin B (mg/kg)\n60\n300\n10\n15mg\n\n\nDietary Fibre (g/kg)\n30\n20\n10\n4g\n\n\n\n\nCreate a model object to hold the problem. E.g., pyo.ConcreteModel().\nCreate variables corresponding to each ingredient. E.g., pyo.Var(within=pyo.NonNegativeReals).\nCreate an objective function to minimise the total cost. E.g., pyo.Objective(expr=..., sense=pyo.minimize).\nCreate constraints for each of the nutritional requirements. E.g., pyo.Constraint(expr=...).\nSolve the linear program. E.g., solver = pyo.SolverFactory('glpk') ; results = solver.solve(model, tee=True) ; model.pprint(). Does the solution match that of the YouTube video (carrot = 9.5g, cabbage = 38g, cucumber = 294g)?\nLet’s suppose that cucumbers aren’t available. There are a couple of ways we could achieve this - for example, we could rebuild with the third column removed. Alternatively, we could add an equality constraint on the problem (cucumber = 0)."
  },
  {
    "objectID": "optim/week9.html#exercise-2---a-simple-diet-problem-extended",
    "href": "optim/week9.html#exercise-2---a-simple-diet-problem-extended",
    "title": "Week 9: Linear programming",
    "section": "Exercise 2 - a simple diet problem extended",
    "text": "Exercise 2 - a simple diet problem extended\nThe goal with this exercise is to simplify the construction of the objective function and the constraints. Often data is provided in tableaus (as above) and instead of manually typing out constraints, we can use loops over the rows/columns of the table. This may not seem simpler for this small example, but it will be significantly easier for large problems.\n\nRead slides 28-30 of the Pyomo Workshop Slides (link above; “Simple Modeling Example: Classic Knapsack Problem” onwards). How might you create a similar structure for the diet problem?\nUse the variables (carrot, cabbage, cucumber) as the indices, with the cost and nutritional content as dictionaries (e.g., cost = {'carrot': 0.75, ...} and vitaminA = {'carrot': 35}). Create the full problem in Pyomo, solve it, and check your answer matches with exercise 1.\nUsing dictionaries, it was possible to simplify the problem so we have a single variable (with indices ['carrot', 'cabbage', 'cucumber']), but all the constraints are still defined separately. To store all the constraint information in a single table, we can create a dictionary of the form nutrition = {('carrot', 'vitamin A'): 35, ('carrot', 'vitamin B'): 60, ..., ('cucumber', 'fibre'): 10}. Create a dictionary for the nutrition and a separate dictionary for the requirements.\nRather than give names to individual constraints, it is possible to create a list of constraints in Pyomo. This enables us to use loops to create many constraints easily. The form of the command is\nmodel.constraints = pyo.ConstraintList()\nfor n in nutrient_names:\n   model.constraints.add(...)\nHow can you use this form to condense the creation of all the constraints? Solve the problem and check that your results match your previous results.\n\nCreating a dictionary by hand in this way is quite painful. We’d usually load one in from a spreadsheet directly - see the next exercise."
  },
  {
    "objectID": "optim/week9.html#exercise-3---a-bigger-diet-problem",
    "href": "optim/week9.html#exercise-3---a-bigger-diet-problem",
    "title": "Week 9: Linear programming",
    "section": "Exercise 3 - a bigger diet problem",
    "text": "Exercise 3 - a bigger diet problem\nIn this problem, we have a much bigger and more realistic data set to work with. In this case you would not want to work by hand. Instead, we will use the approaches developed in exercise 2 to solve the problem.\n\nDownload the data files:\n\noptim-09-lab-FoodContentsData.csv\noptim-09-lab-FoodPriceData.csv\noptim-09-lab-NutritionalRequirementsData.csv\n\nOpen each one in Excel (or similar) to familiarise yourself with the data.\nImport Pandas to read the CSV files: import pandas as pd.\nLoad the data files using data = pd.read_csv(filename, index_col=0).\nThe list of foods can be extracted from the food price data by taking the first column: foods = prices.index.values.tolist(). Similarly, the list of nutrient names can be taken from the first column of the nutritional requirements: nutrient_names = requirements.index.values.tolist().\nConvert the data files into dictionaries using data_dict = data.stack().to_dict().\nSet up your linear programming problem as in exercise 2 and solve it.\n\nNote that there are both minimum and maximum nutritional requirements.\n\n\nThe solution that I get is:\nFrozen Broccoli  =  0.0\nCarrots, Raw  =  0.257921686004706\nCelery, Raw  =  0.0\nFrozen Corn  =  0.0\nLettuce, Iceberg,Raw  =  0.0\nPeppers, Sweet, Raw  =  0.0\nPotatoes, Baked  =  6.11992356370029\nTofu  =  0.0\nRoasted Chicken  =  0.0\nSpaghetti W/ Sauce  =  0.0\nTomato,Red,Ripe,Raw  =  0.0\nApple, Raw, w/Skin  =  0.0\nBanana  =  0.0\nGrapes  =  0.0\nKiwifruit, Raw, Fresh  =  0.0\nOranges  =  0.0\nBagels  =  0.0\nWheat Bread  =  0.0\nWhite Bread  =  0.0\nOatmeal Cookies  =  0.0\nApple Pie  =  0.0\nChocolate Chip Cookies  =  0.0\nButter, Regular  =  0.0\nCheddar Cheese  =  0.0\n3.3% Fat, Whole Milk  =  0.0\n2% Lowfat Milk  =  0.0\nSkim Milk  =  2.00270396628937\nPoached Eggs  =  0.0\nScrambled Eggs  =  0.0\nBologna, Turkey  =  0.0\nFrankfurter, Beef  =  0.0\nHam, Sliced, Extralean  =  0.0\nKielbasa, Pork  =  0.0\nCap'N Crunch  =  0.0\nCheerios  =  0.0\nCorn Flakes, Kellogg'S  =  0.0\nRaisin Bran, Kellogg'S  =  0.0\nRice Krispies  =  0.0\nSpecial K  =  0.0\nOatmeal  =  0.0\nMalt-O-Meal, Choc  =  0.0\nPizza w/Pepperoni  =  0.0\nTaco  =  0.0\nHamburger w/Toppings  =  0.0\nHotdog, Plain  =  0.0\nCouscous  =  0.0\nWhite Rice  =  0.117814898855647\nMacaroni, cooked  =  0.0\nPeanut Butter  =  3.92286261080103\nPork  =  0.0\nSardines in Oil  =  0.0\nWhite Tuna in Water  =  0.0\nPopcorn, Air-Popped  =  0.15278313277272\nPotato Chips, BBQ  =  0.0\nPretzels  =  0.0\nTortilla Chips  =  0.0\nChicken Noodle Soup  =  0.0\nSplt Pea&Ham Soup  =  0.0\nVeggie Beef Soup  =  0.0\nNew Eng Clam Chwd  =  0.0\nTomato Soup  =  0.0\nNew Eng Clam Chwd, w/Mlk  =  0.0\nCrm Mshrm Soup, w/Mlk  =  0.0\nBean Bacon Soup, w/Watr  =  0.0"
  },
  {
    "objectID": "optim/week8.html",
    "href": "optim/week8.html",
    "title": "Week 8: Gradient-free optimisation",
    "section": "",
    "text": "In the following exercises you will need to develop some (simple) code to implement gradient-free optimisation algorithms. You are free to use any resources available to develop your codes, but I recommend trying to understand the details of how they work to build up intuition for later in the course.\nThe purpose of all these exercises is to help you understand the strengths and weakness of different approaches. In optimisation, there is no “one size fits all”; different problems will be best solved using different methods.\nAlmost all optimisation packages will implement Nelder-Mead as a simple, low-dimensional, gradient-free optimisation algorithm. However, population-based methods are less commonly found in existing packages because they require much more tuning towards the specific problem of interest."
  },
  {
    "objectID": "optim/week8.html#supplementary-material",
    "href": "optim/week8.html#supplementary-material",
    "title": "Week 8: Gradient-free optimisation",
    "section": "Supplementary material",
    "text": "Supplementary material\n\nAlgorithms for Optimisation - Direct Methods (Nelder-Mead)\nAlgorithms for Optimisation - Stochastic Methods (Simulated Annealing)\nAlgorithms for Optimisation - Population Methods (Genetic Algorithms and Particle Swarm Optimisation)\nVarious optimisation algorithm implementations\n\nPython - scipy.optimize\nJulia - Optim.jl\nMATLAB - Optimization Toolbox\n\nFunctional programming in NumPy - specifically the apply_along_axis and apply_over_axes functions"
  },
  {
    "objectID": "optim/week8.html#notes-from-the-demo-session",
    "href": "optim/week8.html#notes-from-the-demo-session",
    "title": "Week 8: Gradient-free optimisation",
    "section": "Notes from the demo session",
    "text": "Notes from the demo session\n\nShared code\nDifferent ways to generate the objective function landscape"
  },
  {
    "objectID": "optim/week8.html#notation",
    "href": "optim/week8.html#notation",
    "title": "Week 8: Gradient-free optimisation",
    "section": "Notation",
    "text": "Notation\nThroughout this unit I use superscripts in brackets to denote iteration number. Superscripts without brackets denote to the power of. I.e., \\(x^{(3)}\\) is the value of \\(x\\) on the third iteration, whereas \\(x^3\\) is the third power of \\(x\\)."
  },
  {
    "objectID": "optim/week8.html#exercise-1",
    "href": "optim/week8.html#exercise-1",
    "title": "Week 8: Gradient-free optimisation",
    "section": "Exercise 1",
    "text": "Exercise 1\nAckley’s function is a commonly used optimisation test function with many local minima. It is given by \\[\nf(\\mathbf{x}) = -a\\exp\\left(-b\\sqrt{\\frac{1}{d}\\sum_{i=1}^d x_i^2}\\right) - \\exp\\left(\\frac{1}{d}\\sum_{i=1}^d \\cos(c x_i)\\right) + a + \\exp(1).\n\\] Typically, \\(a=20\\), \\(b=0.2\\), \\(c=2\\pi\\). Code for Ackley’s function is below.\n\nVisualise Ackley’s function in two dimensions for \\(-30\\le x\\le 30\\). What do you notice about this function? (Also see different ways to generate the objective function landscape.)\nImplement Particle Swarm Optimisation on Ackley’s function in 2D using a population of 10 randomly placed particles. Visualise the step-by-step movement of the particles (e.g., draw lines between the each point each particle visits to show the time history).\nChange the hyperparameters of the PSO algorithm (e.g., momentum, number of particles, etc). How is the convergence of the method affected versus computational time?\nIncrease the number of dimensions to 10. How does the performance of the algorithm change?\n[Extension] Break the overall population into sub-swarms, so that you now track a global minimum, a sub-swarm minimum, and a personal minimum, with corresponding forces on each particle in those three directions. How does this change the behaviour of the algorithm?\n\n\nPython code for Ackley’s function\ndef ackley(x, a=20, b=0.2, c=2*np.pi):\n    d = len(x)\n    return -a * np.exp(-b * np.sqrt(np.sum(np.square(x))/d)) - \\\n        np.exp(np.sum(np.cos(c * x))/d) + a + np.exp(1)\n\n\nJulia code for Ackley’s function\nfunction ackley(x, a=20, b=0.2, c=2π)\n    d = length(x)\n    return -a * exp(-b * sqrt(sum(x.^2)/d)) - \n        exp(sum(cos.(c .* x))/d) + a + exp(1)\nend"
  },
  {
    "objectID": "optim/week8.html#exercise-2",
    "href": "optim/week8.html#exercise-2",
    "title": "Week 8: Gradient-free optimisation",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nThe Travelling Salesman Problem is a combinatorial problem where you need to choose the optimal ordering of cities to visit (and sell your goods in) such that you never visit the same city twice and you minimise the total distance travelled.\nWe can find good (near optimal) solutions using a genetic algorithm.\nThe first question is how to represent a journey. The easiest way is to use a vector of integers, where each integer represents a city. (E.g., 0 = London, 1 = Birmingham, etc.) The objective function is then the sum of the Euclidean distances between each city, in the order given by the solution vector.\nThe constraints on the problem will be satisfied if each city is only in the vector once.\nAssuming that the start and end points can be different (i.e., you don’t need to return to your starting position), for a list of 20 cities there are \\(20! = 2,432,902,008,176,640,000\\) possible combinations. Exhaustive search is not feasible.\n\nWhat might a suitable crossover function be? (I.e., combining two parents to generate a child vector.) Remember that the constraints must still be satisfied.\nWhat might a suitable mutation function be? (I.e., modifying a child vector to give a slightly different vector.)\nWrite code for each element of the genetic algorithm\n\nGenerate the initial population.\nCalculate the fitness of each solution.\nSelect solutions to breed from.\nApply the crossover function to each pair of solutions.\nApply the mutation function to ecah child solution.\nReplace the population with the child population.\nGo to 2 until the termination criteria have been met.\n\nRun your code with the UK cities data provided below.\n\n\nTest data\nObtained from ChatGPT with the prompt “Give me the coordinates of the top 20 cities in the UK as a Python list”.\nuk_cities_coordinates = [\n    [\"London\", 51.5074, -0.1278],\n    [\"Birmingham\", 52.4862, -1.8904],\n    [\"Glasgow\", 55.8642, -4.2518],\n    [\"Liverpool\", 53.4084, -2.9916],\n    [\"Bristol\", 51.4545, -2.5879],\n    [\"Manchester\", 53.4808, -2.2426],\n    [\"Sheffield\", 53.3811, -1.4701],\n    [\"Leeds\", 53.8008, -1.5491],\n    [\"Edinburgh\", 55.9533, -3.1883],\n    [\"Leicester\", 52.6369, -1.1398],\n    [\"Coventry\", 52.4068, -1.5197],\n    [\"Kingston upon Hull\", 53.7676, -0.3274],\n    [\"Cardiff\", 51.4816, -3.1791],\n    [\"Nottingham\", 52.9548, -1.1581],\n    [\"Stoke-on-Trent\", 53.0027, -2.1794],\n    [\"Southampton\", 50.9097, -1.4044],\n    [\"Newcastle upon Tyne\", 54.9783, -1.6174],\n    [\"Portsmouth\", 50.8198, -1.0878],\n    [\"Bradford\", 53.7950, -1.7594],\n    [\"Belfast\", 54.5973, -5.9301],\n]"
  },
  {
    "objectID": "optim/week8.html#exercise-3-extension",
    "href": "optim/week8.html#exercise-3-extension",
    "title": "Week 8: Gradient-free optimisation",
    "section": "Exercise 3 (extension)",
    "text": "Exercise 3 (extension)\nApply the Simulated Annealing algorithm to either of the problems (Exercise 1 or Exercise 2) above. The function to generate new solutions in Simulated Annealing can be similar to / the same as your mutation function for the genetic algorithm."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Scientific Computing and Optimisation",
    "section": "",
    "text": "This unit will bring together your previous experience of solving mathematical problems (optimisation, differential equations) and writing computer programmes using Python, Matlab, or Julia. The aim is to provide you with a suite of tools that can be used to transform real-world problems, such as those encountered in the Mathematical and Data Modelling units and final-year projects, into problems that can be efficiently solved on a computer.\n\nUnit timetable\n\nWeek 1: Finite differences and Euler’s method\nWeek 2: ODE boundary value problems\nWeek 3: Diffusion equations in 1D\nWeek 4: First-order PDEs in 1D\nWeek 5: The 2D Poisson equation\nWeek 6: Reading week (no sessions)\nWeek 7: Gradient-based optimisation\nWeek 8: Gradient-free optimisation\nWeek 9: Linear programming\nWeek 10: Integer linear programming\nWeek 11: Optimisation extras and coursework support\nWeek 12: No sessions\n\n\n\nTeaching sessions\n\nMonday 1200–1300 - demo and Q&A session - MVB 1.15\nThursday 1300–1500 - lab session – MVB 1.15\nFriday 1300–1400 - drop-in (optional) - MVB 1.15\n\n\n\nSoftware\nYou can code in Python, Matlab, or Julia. The choice is yours. However, some demos and examples will only be provided in one programming language.\nBefore the unit begins, please ensure that you have a functioning installation of your programming language of choice.\nIf you are coding in Python, then you will need the following packages:\n\nSciPy and NumPy\nMatplotlib\nmemory_profiler\nPyomo\n\nSee installing Pyomo for more details\n\n\nIf you are coding in Matlab, then you will need the optimisation and global optimisation toolboxes.\nIf you are coding in Julia, then you will need the following packages:\n\nOrdinaryDiffEq.jl\nA plotting package (e.g., GLMakie.jl or Plots.jl)\nBenchmarkTools.jl\nJuMP.jl\nAlso see modern Julia workflows\n\nIn Julia these can be installed from the REPL (compilation will take a few minutes):\nimport Pkg\nPkg.add([\"OrdinaryDiffEq\", \"GLMakie\", \"BenchmarkTools\", \"JuMP\"])\n\n\nTeaching staff\n\nDr Matthew Hennessy (unit director): matthew.hennessy@bristol.ac.uk\nProf David Barton (unit lecturer): david.barton@bristol.ac.uk\nMr Jasper Knox (teaching assistant): wa20553@bristol.ac.uk"
  },
  {
    "objectID": "python/numpy.html",
    "href": "python/numpy.html",
    "title": "NumPy, SciPy, and Matplotlib",
    "section": "",
    "text": "NumPy\n\nNumPy is a Python library that enables vectors and matrices to be stored as arrays\nNumPy provides very fast mathematical functions that can operate on these arrays.\n\n\n\nImporting NumPy\nIt is common to import NumPy using the command\n\nimport numpy as np\n\n\n\nDefining arrays\n\nArrays are defined using the array function.\nA vector (1D array) can be created by passing a list to array\n\nExample: Create the vector \\(v = (1, 2, 3)\\)\n\nv = np.array([1, 2, 3])\nprint(v)\n\n[1 2 3]\n\n\nA matrix (2D array) can be created by passing a nested list to array, where each inner list is a row of the matrix\nExample: Create the matrix \\[\nM = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix}\n\\]\n\nM = np.array([ [1, 2], [3, 4] ])\nprint(M)\n\n[[1 2]\n [3 4]]\n\n\n\n\nAccessing elements\n\nIndividual elements in a 1D array can be accessed using square brackets and a numerical index\nIndexing NumPy arrays starts at 0\n\n\n# print the second element of vector v\nprint(v[1])\n\n2\n\n\n\nUse two indices separated by a comma for 2D arrays (first index = row, second index = column)\n\n\n# print the entry in the second row, first column of M\nprint(M[1, 0])\n\n3\n\n\n\n\nAccessing sequential elements\nA colon (:) can be used to access sequential elements in an array:\n\nv = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\nprint(v[:])\n\n[1 2 3 4 5 6 7 8 9]\n\n\nThe notation v[a:b] will access entries starting at index \\(a\\) and ending at \\(b-1\\)\n\n# print the third to fifth entries\nprint(v[2:5])\n\n[3 4 5]\n\n\n\n\nSome useful functions for creating arrays\n\nlinspace(a, b, N) creates a 1D array with \\(N\\) uniformly spaced entries between \\(a\\) and \\(b\\) (inclusive)\neye(N) creates the \\(N \\times N\\) identity matrix\nones(dims) creates arrays filled with ones, where dims is a tuple of integers that describes the dimensions of the array\nzeros(dims) creates arrays filled with zeros\nrandom.random(dims) creates an array with random numbers between 0 and 1 from a uniform distribution\n\n\n\nOperations on NumPy arrays\nMany mathematical operations can be performed immediately\n\n+ and -: element-by-element addition and subtraction\n*: scalar multiplication or element-by-element multiplication\ndot(a,b): dot product of two 1D arrays a and b\n@: matrix multiplication\n\nNumPy comes with mathematical functions that can operate on arrays (e.g. trig functions, exp, log) * np.sin(x): applies the sin function to each element of x\n\n\nLinear algebra with NumPy\nThe linalg module of NumPy has functions for linear algebra. For example:\n\nlinalg.solve(A,b): Solve a linear system of equations of the form \\(Ax = b\\)\nlinalg.det(A): Compute determinants of \\(A\\)\nlinalg.inv(A): Compute the inverse of \\(A\\), ie \\(A^{-1}\\)\nlinalg.eig(A): Compute the eigenvalues and eigenvectors of \\(A\\)\n\n\n\nSciPy\nIs a Python package that contains functions for a wide range of mathematical problems\n\nSpecial functions, e.g. Bessel functions\nSolving nonlinear equations\nOptimisation\nInterpolation\nIntegration (including solving ODEs)\nLinear algebra (including sparse linear algebra)\nand more\n\nThe SciPy package is imported using the code\n\nimport scipy\n\nAs part of this unit, we will be solving nonlinear algebraic equations and optimisation problems\n\nscipy.optimize.root solves algebraic equations\nscipy.optimise.minimize minimises a scalar function with multiple variables\n\nWe will also learn about other SciPy functions that are useful for finding the numerical solution to PDEs and optimisation problems.\n\n\nMatplotlib\n\nUsed for visualising data in Python (eg creating plots)\nWorks well with NumPy\n\nUsually imported using\n\nimport matplotlib.pyplot as plt\n\n\n\nA basic example\nPlot \\(y = \\sin(x)\\) from \\(x = 0\\) to \\(x = 2\\pi\\)\n\nx = np.linspace(0, 2 * np.pi, 100)\ny = np.sin(x)\n\nplt.plot(x, y)\nplt.show()\n\n\n\n\n\n\n\n\n\nThere are many options that can edited to make figures look nicer\nThere are also many different styles of figures (e.g. contour plots, scatter plots)\nSee https://github.com/rougier/matplotlib-tutorial for a good overview of the options\n\n\n# use latex fonts and use a fontsize of 16 everywhere\nplt.rcParams.update({\"text.usetex\": True, \"font.size\": 16})\n\n# plot\nplt.plot(x, y, linewidth=2, color='black')\n\n# add labels to the axes\nplt.xlabel(r'$x$')\nplt.ylabel(r'$\\sin(x)$')\n\n# show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSummary\n\nNumPy provides functionality for storing numerical data as arrays and performing operations on these\nSciPy contains functions for solving a wide variety of mathematical problems\nMatplotlib is for visualising data"
  },
  {
    "objectID": "python/python_review.html",
    "href": "python/python_review.html",
    "title": "Python fundamentals",
    "section": "",
    "text": "Overview\n\nTo provide an overview of core Python functionality and programming techniques\nRefresh your memory of Python syntax\nThis page only covers the basics and is by no means exhaustive.\n\n\n\nBasic variable types\n\nInts: integers; e.g. a = 2\nFloats: floating-point numbers with decimals; e.g. a = 2.0\nStrings: collection of characters contained in single or double quotes; individual characters can be accessed using an index (starting at 0)\n\n\na = 2\nb = 2.0\ns = \"hello\"\nprint(s[0])\n\nh\n\n\nUse the int, float, and str functions to convert between types\n\na = 2.00\nprint(int(a))\n\n2\n\n\n\n\nMathematical operations\n\n\n\nOperation\nDescription\nExample\n\n\n\n\n+\nAddition\n5 + 3 = 8\n\n\n-\nSubstraction\n5 - 3 = 2\n\n\n*\nMultiplication\n5 * 3 = 15\n\n\n/\nDivision\n5 / 3 = 1.666…\n\n\n//\nFloor division (round down to an integer)\n5 // 3 = 1\n\n\n%\nModulo (compute remainder)\n5 % 3 = 2\n\n\n**\nExponent\n5 ** 3 = 125\n\n\n\n\n\nBoolean operations\n\n\n\nOperation\nDescription\nExample\nValue\n\n\n\n\n==\nIs equal?\n1 == 2\nFalse\n\n\n!=\nIs not equal?\n1 != 2\nTrue\n\n\n&lt;\nLess than?\n1 &lt; 2\nTrue\n\n\n&gt;\nGreater than?\n1 &gt; 2\nFalse\n\n\n&lt;=\nLess than or equal to?\n1 &lt;= 2\nTrue\n\n\n&gt;=\nGreater than or equal to?\n1 &gt;= 2\nFalse\n\n\n\n\n\nLogical operations\n\n\n\nOperation\nDescription\nExample\nValue\n\n\n\n\nand\nAre both true?\n1 &lt; 2 and 3 &lt; 2\nFalse\n\n\nor\nIs one true?\n1 &lt; 2 or 3 &lt; 2\nTrue\n\n\nnot\nNegate the conditional\nnot(1 &lt; 2)\nFalse\n\n\n\n\n\nData structures\n\n\n\nType\nExample\nCharacteristics\n\n\n\n\nList\nL = [1, 1.0, ‘one’]\nMutable, iterable, ordered\n\n\nTuple\nt = (1, 1.0, ‘one’)\nImmutable, iterable, ordered\n\n\nSet\ns = {1, 1.0, ‘one’}\nMutable, iterable, unordered, unique\n\n\nDictionary\nd = {‘a’:1, ‘b’:2, ‘c’:3}\nMutable, iterable, ordered\n\n\n\n\nMutable: Can be modified\nImmutable: Cannot be modified\nOrdered: Elements can be accessed using an index or a key\n\n\n\nData structures continued\n\nUse list, tuple, and set functions to convert between types\nElements in lists and tuples can be accessed using an integer index (starting at 0)\nElements in dictionaries are accessed using keys\n\n\n# create a list and print the first value\nL = [1, 2, 3]\nprint(L[0])\n\n1\n\n\n\n# create a dictionary of gravitational accelerations in m/s2\ng = {'Earth': 9.8, 'Mars':3.7, 'Jupiter':25}\nprint(g['Earth'])\n\n9.8\n\n\n\n\nIf statements\n\nUsed to make a decision in a program\nRuns an indented block of code if a conditional statement is true\n\n\ni = 20\n\nif i &lt; 10:\n    print(\"Doing something because i &lt; 10 and the code is indented\")\n    \nprint('Printing non-indented code for all values of i')\n\nPrinting non-indented code for all values of i\n\n\n\n\nIf-else statements\n\nCreates two pathways, the choice depends on whether a condition is true or false\n\n\ni = 20\n\nif i &lt; 10:\n    print('Doing something because i &lt; 10')\nelse:\n    print('Doing something else i &gt;= 10')\n\nDoing something else i &gt;= 10\n\n\n\n\nIf-else-elif statements\n\nCreates multiple pathways, the choice depends on which condition is true\n\n\ni = 20\n\nif i &lt; 10:\n    print('Doing something because i &lt; 10')\nelif i &gt; 10:\n    print('Doing something else because i &gt; 10')\nelse:\n    print('Doing something different from the other two cases')\n\nDoing something else because i &gt; 10\n\n\n\n\nFor loops\n\nFor repeating code a fixed number of times\n\nfor e in collection:\n    # run indented code\n\nThe indented code is run until e has taken on every value in collection (which is an iterable object like a list or tuple)\n\n\n# print the numbers from 0 to 10\nfor i in range(11):\n    print(i, end=\" \")\n\n0 1 2 3 4 5 6 7 8 9 10 \n\n\n\n# capitalise words in a list\nL = ['red', 'blue', 'green']\nfor c in L:\n    print(c.capitalize(), end=\", \")\n\nRed, Blue, Green, \n\n\n\n\nWhile loops\n\nFor repeating code until a condition becomes false\n\nwhile condition:\n    # run indented code\n\nWhile loops are useful when you don’t know how many times to repeat code\nBeware of infinite loops!\n\n\n# compute the square numbers that are smaller than 450\nn = 1\n\nwhile n**2 &lt; 450:\n    print(n**2, end=\", \")\n    n += 1\n\n1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, 256, 289, 324, 361, 400, 441, \n\n\n\n\nBreak and continue\n\nbreak is used to terminate a loop\ncontinue is used to skip an iteration in a loop\n\n\nfor i in range(10):\n    print(i, end = \" \")\n\n0 1 2 3 4 5 6 7 8 9 \n\n\n\nfor i in range(10):\n    if i == 4:\n        break\n    print(i, end = \" \")\n\n0 1 2 3 \n\n\n\nfor i in range(10):\n    if i == 4:\n        continue\n    print(i, end = \" \")\n\n0 1 2 3 5 6 7 8 9 \n\n\n\n\nFunctions\n\nFunctions are mini-programs based on a collection of code that has been given a name\nFunctions are defined using the def keyword\nFunction inputs are called arguments\nThe return keyword is used to output data from a function\n\n\n# add two numbers a and b together\ndef my_sum(a, b):\n    c = a + b\n    return c\n\nc = my_sum(3, 6)\nprint(c)\n\n9\n\n\n\n\nScripts, modules, and packages\n\nModules are Python files (.py) that contain variables, functions, etc\nPackages are folders (directories) that contain modules\nScripts are top-level Python files that import packages and modules\nScripts are run (e.g. in Spyder) not modules/packages\n\nA typical file structure might look like this:\nemat30008/\n|--- main.py\n|--- circle.py\nwhere main.py is a script that imports the module circle.py\n\n\nImporting modules and packages\n\nThe import keyword is used to load Python code from modules and packages\nThere are many ways to do this; see EMAT10007 notes for more details\n\n\n# import the math package\nimport math\n\n# print the variable pi from the math package\nprint(math.pi)\n\n3.141592653589793\n\n\n\n\nSummary\nThese slides covered core Python functionality\n\nOperations, data types, control flow, loops, functions, modules and packages\n\nTopics not covered but which you are expected to know:\n\nVariable scope (local, global), keyword and default arguments, classes, file input and output"
  },
  {
    "objectID": "python/overview.html",
    "href": "python/overview.html",
    "title": "Coding",
    "section": "",
    "text": "This page contains some useful info on programming."
  },
  {
    "objectID": "python/overview.html#python-basics",
    "href": "python/overview.html#python-basics",
    "title": "Coding",
    "section": "Python basics",
    "text": "Python basics\nUse the links below to refresh your knowledge of coding in Python:\n\nOverview of Python fundamentals\nOverview of NumPy, SciPy, and Matplotlib"
  },
  {
    "objectID": "python/overview.html#timing-your-code",
    "href": "python/overview.html#timing-your-code",
    "title": "Coding",
    "section": "Timing your code",
    "text": "Timing your code\nUse the link below to learn how to time your Python or Matlab code:\n\nTiming Python or Matlab code"
  },
  {
    "objectID": "optim/week7.html",
    "href": "optim/week7.html",
    "title": "Week 7: Gradient-based optimisation",
    "section": "",
    "text": "In the following exercises you will need to develop some (simple) code to implement gradient-based optimisation algorithms. You are free to use any resources available to develop your codes, but I recommend trying to understand the details of how they work to build up intuition for later in the course.\nThe purpose of all these exercises is to help you understand the strengths and weakness of different approaches. In optimisation, there is no “one size fits all”; different problems will be best solved using different methods.\nMost optimisation toolboxes only implement the more sophisticated methods (e.g., Adam, BFGS, Conjugate Gradient, etc). These can be good for checking your results and performance comparisons."
  },
  {
    "objectID": "optim/week7.html#supplementary-material",
    "href": "optim/week7.html#supplementary-material",
    "title": "Week 7: Gradient-based optimisation",
    "section": "Supplementary material",
    "text": "Supplementary material\n\nAlgorithms for Optimisation - Local descent (line search methods)\nAlgorithms for Optimisation - First-order gradient\nVarious optimisation algorithm implementations\n\nPython - scipy.optimize\nJulia - Optim.jl\nMATLAB - Optimization Toolbox"
  },
  {
    "objectID": "optim/week7.html#notation",
    "href": "optim/week7.html#notation",
    "title": "Week 7: Gradient-based optimisation",
    "section": "Notation",
    "text": "Notation\nThroughout this unit I use superscripts in brackets to denote iteration number. Superscripts without brackets denote to the power of. I.e., \\(x^{(3)}\\) is the value of \\(x\\) on the third iteration, whereas \\(x^3\\) is the third power of \\(x\\)."
  },
  {
    "objectID": "optim/week7.html#exercise-1",
    "href": "optim/week7.html#exercise-1",
    "title": "Week 7: Gradient-based optimisation",
    "section": "Exercise 1",
    "text": "Exercise 1\nConsider the minimisation of the objective function \\[\n    f(x,y)=2x^2+5y^2-2xy -2x-8y\n\\] of two unconstrained variables \\(x\\) and \\(y\\).\n\n[Coordinate descent algorithm] Working by hand. Freeze \\(x=0\\), and find the location \\(y^*\\) of the minimum of the function \\(f(0,y)\\) of one variable \\(y\\). Then freeze \\(y=y^*\\) and find the location \\(x^*\\) of the minimum of the function \\(f(x,y^*)\\) of one variable \\(x\\).\n[Gradient descent algorithm] Working by hand. Find \\(\\nabla f\\). Thus, beginning from the origin \\((0,0)\\), perform one step of the gradient descent algorithm. That, is find the \\(\\alpha^{(1)}\\) such that the function \\((0,0)^\\mathrm{T}+\\alpha\\nabla f(0,0)\\) of one variable \\(\\alpha\\) is minimised, and find the corresponding coordinates of the next iterate \\((x^{(1)},y^{(1)})\\).\nUse your favourite package to plot (e.g., contours) of \\(f(x,y)\\) in the quadrant \\(x_1,x_2\\geq0\\) and overlay points and lines corresponding to your part 1. and 2. answers.\nDevelop, exhibit, and explain gradient descent code that finds the minimum value and the location of the minimum of \\(f(x,y)\\) above. (You can write out the gradient by hand rather than using finite differences.) Plot your results on the contour plot from part 3. For stepsize selection, try each of:\n\nUse a fixed step size \\(\\alpha\\) of your choice.\nUse a decaying step size \\(\\alpha^{(k)} = \\alpha^{(1)}\\gamma^{k-1}\\) for \\(\\gamma=0.95\\).\nUse a backtracking line search."
  },
  {
    "objectID": "optim/week7.html#exercise-2",
    "href": "optim/week7.html#exercise-2",
    "title": "Week 7: Gradient-based optimisation",
    "section": "Exercise 2",
    "text": "Exercise 2\nThe Rosenbrock function is a standard test case for many optimisation algorithms because it is ill conditioned (i.e., nasty): \\[\n    f(x,y) = (a - x)^2 + b(y - x^2)^2\n\\] where typically \\(a = 1\\) and \\(b = 100\\). The gradient of the Rosenbrock function is The gradient of the Rosenbrock function is given by\n\\[\n\\nabla f(x,y) =\n\\begin{bmatrix}\n\\frac{\\partial f}{\\partial x} \\\\\n\\frac{\\partial f}{\\partial y}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n-2(a - x) - 4bx(y - x^2) \\\\\n2b(y - x^2)\n\\end{bmatrix}.\n\\]\n\nImplement a backtracking line search so that it can be applied to any objective function and optimisation method. Assume that you have the gradient a I.e., backtracking(rosenbrock, grad_rosenbrock, gradientdescent, [-1.5,-0.5]) should use the backtracking algorithm with the basic gradient descent optimisation algorithm and apply it to the Rosenbrock function. Here rosenbrock and grad_rosenbrock are functions of a single variable \\(u=[x,y]\\) that return the objective function and its gradient, respectively. The function gradientdescent provides the search direction given by the gradient descent algorithm.\nNOTE: all algorithms other than gradient descent require additional values to be stored (e.g., momentum). Your implementation should be able to deal with this; a nice solution would be something like\ndef momentum(objfunc, stepsize, position, extra):\n    if extra is None:  # create a new vector to store momentum\n        extra = np.zeros_like(position)\n    # Calculate new position based on the stepsize given by the line search\n    # ...\n    # Return the new position and updated momentum vector\n    return (position, extra)\nImplement each of the following optimisation algorithms in a form that works with your backtracking line search from Q1.\n\nGradient descent (basic algorithm)\nGradient descent with momentum\nRMSProp\nAdam\n\nTry each of the algorithms on the Rosenbrock function. Compare the number of iterations required for convergence for each algorithm. What conclusions can you draw from this?"
  },
  {
    "objectID": "optim/week7.html#exercise-3-extension",
    "href": "optim/week7.html#exercise-3-extension",
    "title": "Week 7: Gradient-based optimisation",
    "section": "Exercise 3 (extension)",
    "text": "Exercise 3 (extension)\nBelow are three additional objective functions commonly used to test the performance of gradient-based optimisation algorithms. Use \\(n=2\\) in each case. (Feel free to test the performance in more dimensions!)\nApply your code from exercise 2 to each of these test cases. Visualise the results.\n\nSphere Function\nThe Sphere function is a simple convex function used for testing optimisation algorithms\n\\[\nf(x) = \\sum_{i=1}^{n} x_i^2.\n\\]\n\n\nRastrigin Function\nThe Rastrigin function is a non-convex function used to test the performance of optimisation algorithms on multimodal landscapes\n\\[\nf(x) = 10n + \\sum_{i=1}^{n} \\left[ x_i^2 - 10 \\cos(2 \\pi x_i) \\right].\n\\]\n\n\nAckley Function\nThe Ackley function is another non-convex function with many local minima, making it a challenging test case for optimisation algorithms\n\\[\nf(x) = -20 \\exp \\left( -0.2 \\sqrt{0.5 \\sum_{i=1}^{n} x_i^2} \\right) - \\exp \\left( 0.5 \\sum_{i=1}^{n} \\cos(2 \\pi x_i) \\right) + \\exp(1) + 20.\n\\]"
  },
  {
    "objectID": "optim/installing-pyomo.html",
    "href": "optim/installing-pyomo.html",
    "title": "Installing Pyomo",
    "section": "",
    "text": "Pyomo is a Python wrapper around various solvers written in other languages. While Pyomo itself can be installed easily via pip or conda, it can be harder to install the solvers."
  },
  {
    "objectID": "optim/installing-pyomo.html#installation-via-conda-existing-install",
    "href": "optim/installing-pyomo.html#installation-via-conda-existing-install",
    "title": "Installing Pyomo",
    "section": "Installation via Conda (existing install)",
    "text": "Installation via Conda (existing install)\nIf you have installed Python via Miniconda or Anaconda, then you can install the required packages directly with conda.\nFrom a terminal (Windows start menu → Terminal), run\nconda install -c conda-forge pyomo glpk ipopt\nTo install Pyomo and the GLPK/Ipopt solvers. If the command is not found, you might need to run this command from an Anaconda command line (it might be an option on your start menu)."
  },
  {
    "objectID": "optim/installing-pyomo.html#installation-via-conda-new-install",
    "href": "optim/installing-pyomo.html#installation-via-conda-new-install",
    "title": "Installing Pyomo",
    "section": "Installation via Conda (new install)",
    "text": "Installation via Conda (new install)\nDownload and install Miniconda. Since this is a new installation, you will need to install various packages. I recommend running the following from a terminal (Windows start menu → Terminal) to install common packages:\nconda install -c conda-forge scipy numpy matplotlib ipython pyomo glpk ipopt\nIf the command is not found, it means that conda is not on your system path (i.e., the list of folders that Windows searches for programs to run). If you installed Miniconda in the default place, you should be able to change to the installation folder and run the command from there:\ncd \\Users\\Your Username\\AppData\\Local\\miniconda3\\Scripts\nconda install -c conda-forge scipy numpy matplotlib ipython pyomo glpk ipopt\nor (on some installs)\ncd \\Users\\Your Username\\miniconda3\\Scripts\nconda install -c conda-forge scipy numpy matplotlib ipython pyomo glpk ipopt\nIf you use PyCharm, Spyder, or VS Code, you will need to change the Python interpreter they use to the new one.\n\nPyCharm instructions\nSpyder instructions - see “How do I get Spyder to work with my existing Python packages/environment”\nVS Code instructions"
  },
  {
    "objectID": "optim/installing-pyomo.html#installing-glpk-directly",
    "href": "optim/installing-pyomo.html#installing-glpk-directly",
    "title": "Installing Pyomo",
    "section": "Installing GLPK directly",
    "text": "Installing GLPK directly\nIf you can install Pyomo using pip (e.g., pip install pyomo), you can then add solvers manually. GLPK is a basic solver but sufficient for most of our needs. You can download winglpk-4.65.zip from https://sourceforge.net/projects/winglpk/files/winglpk/GLPK-4.65/. You need two files from the zip: w64\\glpk_4_65.dll and w64\\glpsol.exe. The installation guide of GLPK recommends adding these files to the folder C:\\Windows\\System32 or another folder that is present on your path (i.e., the list of folders that Windows searches for programs to run)."
  },
  {
    "objectID": "optim/installing-pyomo.html#using-google-colab",
    "href": "optim/installing-pyomo.html#using-google-colab",
    "title": "Installing Pyomo",
    "section": "Using Google Colab",
    "text": "Using Google Colab\nIf you have a Google account, you have free access to Colab. This provides a notebook-style interface to cloud-based computers with Python already installed. Simply create a new notebook in Colab and add these lines to the top of the notebook:\n!pip install pyomo\n!apt install -y -qq glpk-utils\nThese commands need to be run each time you re-open the notebook, but they only need to be run once per session. As such, it is best to keep them in a cell that is separate from the rest of your work at the top of the notebook."
  },
  {
    "objectID": "optim/week8-lab.html",
    "href": "optim/week8-lab.html",
    "title": "Week 8 lab",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef ackley(x, a=20, b=0.2, c=2*np.pi):\n    d = len(x)\n    return -a * np.exp(-b * np.sqrt(np.sum(np.square(x))/d)) - \\\n        np.exp(np.sum(np.cos(c * x))/d) + a + np.exp(1)"
  },
  {
    "objectID": "optim/week8-lab.html#set-up",
    "href": "optim/week8-lab.html#set-up",
    "title": "Week 8 lab",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef ackley(x, a=20, b=0.2, c=2*np.pi):\n    d = len(x)\n    return -a * np.exp(-b * np.sqrt(np.sum(np.square(x))/d)) - \\\n        np.exp(np.sum(np.cos(c * x))/d) + a + np.exp(1)"
  },
  {
    "objectID": "optim/week8-lab.html#test-different-approaches-to-generating-the-objective-function-surface",
    "href": "optim/week8-lab.html#test-different-approaches-to-generating-the-objective-function-surface",
    "title": "Week 8 lab",
    "section": "Test different approaches to generating the objective function surface",
    "text": "Test different approaches to generating the objective function surface\n\n# Method 1: list comprehension (2D)\ndef method1(n):\n    x = np.linspace(-30, 30, n)  # n points between -30 and 30\n    y = np.linspace(-30, 30, n)  # n points between -30 and 30\n    return (x, y, np.array([[ackley(np.array([i, j])) for i in x] for j in x]))  # 2D array using a list comprehension\n\n%timeit method1(501)\n\n3.75 s ± 75.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\n# Method 2: pre-allocated array (2D)\ndef method2(n):\n    x = np.linspace(-30, 30, n)  # n points between -30 and 30\n    y = np.linspace(-30, 30, n)  # n points between -30 and 30\n    z = np.zeros((n, n))  # pre-allocate the 2D array\n    for i in range(n):\n        for j in range(n):\n            z[i, j] = ackley(np.array([x[i], y[j]]))\n    return (x, y, z)\n\n%timeit method2(501)\n\n3.79 s ± 47.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\n# Method 3: meshgrid with list comprehension (1D)\ndef method3(n):\n    x = np.linspace(-30, 30, n)\n    y = np.linspace(-30, 30, n)\n    (xx, yy) = np.meshgrid(x, y)  # 2D arrays of x and y values separately\n    xy = np.column_stack((xx.flatten(), yy.flatten()))  # 2D array of all combinations of x and y; first column is x and second column is y\n    return (x, y, np.array([ackley(xyi) for xyi in xy]).reshape(xx.shape))\n\n%timeit method3(501)\n\n3.79 s ± 249 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\nSummary\nThere is no discernable difference between the different methods - use whichever comes most naturally!"
  },
  {
    "objectID": "optim/week8-lab.html#plotting",
    "href": "optim/week8-lab.html#plotting",
    "title": "Week 8 lab",
    "section": "Plotting",
    "text": "Plotting\n\n# plot contour lines\n(x, y, z) = method1(1001)\nplt.figure()\nplt.contour(x, x, z, levels=np.linspace(0, 20, 21), colors='black')\nplt.show()"
  },
  {
    "objectID": "optim/week8-lab.html#julia",
    "href": "optim/week8-lab.html#julia",
    "title": "Week 8 lab",
    "section": "Julia",
    "text": "Julia\nCorresponding Julia code (same as method 1 in Python) is given by\nfunction method1(n)\n    x = range(-30, 30, length=n)\n    y = range(-30, 30, length=n)\n    return [ackley([xi, yi]) for xi in x, yi in y]\nend\nwhich when timed gives\njulia&gt; using BenchmarkTools\njulia&gt; @btime method1(501)\n  34.832 ms (753005 allocations: 59.36 MiB)\nwhich is 108 times faster. A small modification to use statically-sized arrays gives a further speed up\nusing StaticArrays\n\nfunction method2(n)\n    x = range(-30, 30, length=n)\n    y = range(-30, 30, length=n)\n    return [ackley(@SVector[xi, yi]) for xi in x, yi in y]\nend\nwhich when timed gives\njulia&gt; @btime method2(501)\n  8.870 ms (2 allocations: 1.92 MiB)\nwhich is now 427 times faster than Python. Summary: Python is slow…"
  },
  {
    "objectID": "optim/overview.html",
    "href": "optim/overview.html",
    "title": "Optimisation: Overview",
    "section": "",
    "text": "The weeks 7-11 will focus on optimisation algorithms and their use in scientific computing. We will cover a range of numerical algorithms including gradient-based methods (e.g., Adam - used for training neural networks), gradient-free methods (e.g., Nelder-Mead and genetic algorithms), linear programming (often used for optimising business processes), and (mixed) integer linear programming.\n\nWeek 7: Gradient-based optimisation\nWeek 8: Gradient-free optimisation\nWeek 9: Linear programming\n\nInstalling Pyomo\n\nWeek 10: Integer programming"
  },
  {
    "objectID": "scicomp/week3.html",
    "href": "scicomp/week3.html",
    "title": "Week 3: Diffusion equations in 1D",
    "section": "",
    "text": "\\[\n\\renewcommand{\\vec}[1]{\\boldsymbol{#1}}\n\\newcommand{\\td}[2]{\\frac{\\mathrm{d}#1}{\\mathrm{d}#2}}\n\\newcommand{\\tdd}[2]{\\frac{\\mathrm{d}^2#1}{\\mathrm{d}#2^2}}\n\\newcommand{\\pd}[2]{\\frac{\\partial#1}{\\partial#2}}\n\\newcommand{\\pdd}[2]{\\frac{\\partial^2#1}{\\partial#2^2}}\n\\]"
  },
  {
    "objectID": "scicomp/week3.html#coursework-style-problem",
    "href": "scicomp/week3.html#coursework-style-problem",
    "title": "Week 3: Diffusion equations in 1D",
    "section": "Coursework-style problem",
    "text": "Coursework-style problem\nThis problem explores the fluid and solid mechanics of coffee brewing. Consider a fresh layer of coffee grains of height \\(H = 10\\) mm. The coffee is on placed top of a perforated metal surface that allows water to pass through it. Let \\(z\\) be an upwards-pointing vertical coordinate such that \\(z = 0\\) corresponds to the bottom of the coffee and \\(z = H\\) corresponds to the top of the coffee. At time \\(t = 0\\), water enters the top surface of the coffee. The water then flows through the coffee grains and leaves through the bottom surface.\nThe coffee grains form a porous solid that deforms as water flows through it. The flow of water through the solid, along with the gravitational force, generates a pressure gradient. The pressure gradient acts on the solid to deform it. The pressure in the coffee grains, \\(p(z,t)\\), satisfies the following equation \\[\\begin{align}\n\\frac{1}{E}\\pd{p}{t} = K \\pdd{p}{z}.\n\\end{align}\\] Here, \\(E = 10^4\\) Pa is the Young’s modulus and \\(K = 5.6 \\times 10^{-10}\\) m\\(^2\\) Pa\\(^{-1}\\) s\\(^{-1}\\) is the hydraulic conductivity. The Young’s modulus measures the stiffness of the porous solid formed by the coffee grains, and \\(K\\) characterises how easy it is for fluid to flow through the coffee grains.\nThe pressure of the coffee is initially at the atmospheric pressure, \\(p(z,0) = p_a\\), where \\(p_a = 101.3\\) kPa. The pressure at the bottom of the coffee can be assumed to be equal to the atmospheric pressure, \\(p(0,t) = p_a\\). To account for the influx of water at the top of the coffee grains, the boundary condition at \\(z = H\\) is given by \\[\\begin{align}\nK \\left(\\pd{p}{z} + \\rho g\\right)_{z = H} = F(t)\n\\end{align}\\] where \\(\\rho= 1000\\) kg m\\(^{-3}\\) is the density of wet coffee, \\(g = 9.81\\) m/s\\(^2\\) is the gravitational acceleration, and \\(F(t)\\) represents the flux of water coming into the coffee. We will assume that the flux is given by \\[\\begin{align}\nF(t) = \\begin{cases} F_0, \\quad 0 \\leq t \\leq 10~\\text{s}, \\\\\n0, \\quad t &gt; 10~\\text{s},\n\\end{cases}\n\\end{align}\\] where \\(F_0 = 2 \\times 10^{-5}\\) m/s, which represents a 10 second injection of water into the coffee.\n\nCalculate the difference in fluid pressure at the top surface, \\(\\Delta p = p(H,t) - p_a\\) after 5, 10, 15, and 30 s have passed. Answers (to 3 significant figures): 652, 1890, 577, -13.9 Pa.\nCompute the steady-state pressure profile and plot. Recall that the steady-state pressure is obtained by assuming that time \\(t\\) is very large and that the solution does not depend on time. How does your steady-state profile compared to the pressure you computed from problem 1? Answer: you should find that your time-dependent solution approaches the steady-state solution.\nThe displacement of the coffee grains, \\(u(z,t)\\), can be determined from the equation \\[\\begin{align}\n\\pd{u}{z} = \\frac{p-p_a}{E}.\n\\end{align}\\] Since coffee cannot pass through the metal surface on which it rests, the displacement at \\(z = 0\\) is zero, \\(u(0,t) = 0\\). The deformed thickness of the coffee layer is given by \\(h(t) = H + u(H,t)\\). Plot how the thickness of the coffee layer changes in time. Is the final thickness of the coffee layer larger or smaller than the initial thickness? Answer: smaller, the coffee layer shrinks."
  },
  {
    "objectID": "scicomp/week3.html#answers-to-selected-exercises",
    "href": "scicomp/week3.html#answers-to-selected-exercises",
    "title": "Week 3: Diffusion equations in 1D",
    "section": "Answers to selected exercises",
    "text": "Answers to selected exercises\n3. (a) Explicit Euler is the fastest because the computational cost of each time step is smaller. (b) Implicit Euler is now the fastest because it now requires less time steps. However, the explicit Euler method is the more accurate method because the time step is smaller.\n5. See figure below"
  },
  {
    "objectID": "scicomp/week4.html",
    "href": "scicomp/week4.html",
    "title": "Week 4: First-order PDEs in 1D",
    "section": "",
    "text": "\\[\n\\renewcommand{\\vec}[1]{\\boldsymbol{#1}}\n\\newcommand{\\td}[2]{\\frac{\\mathrm{d}#1}{\\mathrm{d}#2}}\n\\newcommand{\\tdd}[2]{\\frac{\\mathrm{d}^2#1}{\\mathrm{d}#2^2}}\n\\newcommand{\\pd}[2]{\\frac{\\partial#1}{\\partial#2}}\n\\newcommand{\\pdd}[2]{\\frac{\\partial^2#1}{\\partial#2^2}}\n\\]"
  },
  {
    "objectID": "scicomp/week4.html#answers-to-selected-exercises",
    "href": "scicomp/week4.html#answers-to-selected-exercises",
    "title": "Week 4: First-order PDEs in 1D",
    "section": "Answers to selected exercises",
    "text": "Answers to selected exercises\n\nAs C increases to one, the numerical solution becomes more accurate and there is less numerical diffusion. From the formula for the truncation error, we see the numerical diffusion coefficient is proportional to \\((1 - C)\\). Setting \\(C = 1\\) therefore eliminates numerical diffusion.\nNo boundary conditions are needed\nSee figure below \nSee figure below"
  },
  {
    "objectID": "scicomp/week2.html",
    "href": "scicomp/week2.html",
    "title": "Week 2: ODE BVPs",
    "section": "",
    "text": "\\[\n\\renewcommand{\\vec}[1]{\\boldsymbol{#1}}\n\\newcommand{\\td}[2]{\\frac{\\mathrm{d}#1}{\\mathrm{d}#2}}\n\\newcommand{\\tdd}[2]{\\frac{\\mathrm{d}^2#1}{\\mathrm{d}#2^2}}\n\\newcommand{\\pd}[2]{\\frac{\\partial#1}{\\partial#2}}\n\\newcommand{\\pdd}[2]{\\frac{\\partial^2#1}{\\partial#2^2}}\n\\]"
  },
  {
    "objectID": "scicomp/week2.html#answers-to-selected-exercises",
    "href": "scicomp/week2.html#answers-to-selected-exercises",
    "title": "Week 2: ODE BVPs",
    "section": "Answers to selected exercises",
    "text": "Answers to selected exercises\n3. See figure below.\n\n\n\nAnswer to exercise 3 with \\(\\mu = 100\\).\n\n\n4. You should see that Newton’s method is more likely to converge, assuming you’re using the default options with the built-in solver.\n6. This ODE does not have a solution. Numerical methods will always fail to find a solution."
  },
  {
    "objectID": "scicomp/overview.html",
    "href": "scicomp/overview.html",
    "title": "Scientific Computing: overview",
    "section": "",
    "text": "The first five weeks will focus on how scientific computing can be applied to the numerical solution of ordinary and partial differential equations. Although differential equations appear in many engineering contexts, they usually cannot be solved by hand. Instead, numerical methods are needed to compute an approximate solution.\n\nWeek 1: Finite differences and Euler’s method\nWeek 2: ODE boundary value problems\nWeek 3: Diffusion equations in 1D\nWeek 4: First-order PDEs in 1D\nWeek 5: The 2D Poisson equation"
  }
]